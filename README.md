# Feed-forward-neural-network-with-hyperparameter-optimization
• Feedforward neural nets with hyperparameter optimisation: this project will implement a 
feedforward neural network for a dataset of  choice , and experiment systematically with a number of  hyperparameter configurations, 
e.g. the learning rate, batch size, number of  hidden units, layers, etc. The project will need 
to explore systematic approaches for hyperparameter optimisation such as random or grid 
optimisation or genetic algorithms. Note that the specifics will not be taught directly, you’ll 
need to research and find out how to implement these in Python yourself. You may use any 
software libraries available, as long as referenced. The approaches named above e.g.  come 
with sk_learn and do not need to be implemented from scratch. The neural network’s 
performance should be evaluated in different settings and compared against other 
approaches, such as decision trees, Naive Bayes or other classifiers. Results should be 
supported with visualisations, such as graphs.
